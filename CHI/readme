CHI is an extension of ACE protocol
AXI (AMBA AXI4)
	‚Ä¢	Designed for high-performance, high-bandwidth memory-mapped communication between processors, memory, and peripherals.
	‚Ä¢	Supports:
	‚Ä¢	Multiple outstanding transactions
	‚Ä¢	Out-of-order completion
	‚Ä¢	Burst transfers
But: AXI is non-coherent ‚Äî it doesn‚Äôt handle cache coherence between multiple masters.

‚úÖ Used in:
SoCs with single master or software-managed coherence (e.g., microcontrollers, simple multicore CPUs).

ACE (AXI Coherency Extensions)

To support hardware cache coherency, ARM added ACE on top of AXI.
	‚Ä¢	Introduced snoop channels to maintain coherence across CPU caches.
	‚Ä¢	Added:
	‚Ä¢	AC (Address Channel)
	‚Ä¢	CR (Snoop Request)
	‚Ä¢	CD (Snoop Data)
	‚Ä¢	R / W channels with coherence attributes.

‚öôÔ∏è 2. Problem ‚Äî ACE Was Great, But Limited for SoC Scale-Up
When ARM moved from mobile CPUs to server-class, HPC, and AI accelerators, SoC complexity exploded.
ACE‚Äôs design ‚Äî built around point-to-point snooping ‚Äî became inefficient.

üëâ In short:
AXI/ACE were great for on-chip coherent CPU clusters,
but not for multi-cluster, multi-socket coherent systems.


‚ö° 3. Solution ‚Äî CHI (Coherent Hub Interface)
ARM introduced CHI to overcome these scalability and efficiency limits.
CHI = Coherent Hub Interface
A packet-based, credit-controlled, fully coherent interconnect protocol for high-performance, multi-cluster SoCs.

There are currently seven issues of the CHI protocol: A to G.

+++++++++++====+++++++++++
What is difference between Fully coherent, IO coherent and IO Coherent with dvm Support
+++++++++++===============
A fully coherent agent participates completely in the system‚Äôs cache coherency protocol ‚Äî just like a CPU.

It can:
	‚Ä¢	Issue coherent requests (reads/writes that snoop other caches)
	‚Ä¢	Respond to snoop requests
	‚Ä¢	Hold dirty data in its cache hierarchy
	‚Ä¢	Participate in DVM (Distributed Virtual Memory) transactions (TLB invalidations, maintenance ops)

‚úÖ Examples:
	‚Ä¢	ARM Cortex-A CPUs
	‚Ä¢	Coherent GPU clusters (in integrated SoCs)
	‚Ä¢	L2 cache coherent accelerators (like ARM‚Äôs CMN-based ML engines)

(B) I/O Coherent

üí° Definition

An I/O coherent agent (like a DMA or PCIe device) does not maintain its own cache,
but can access data that might be cached in CPU caches coherently ‚Äî i.e., it can snoop CPU caches via the interconnect.

It means:
	‚Ä¢	The I/O device doesn‚Äôt keep cachelines.
	‚Ä¢	But the interconnect snoops CPU caches on behalf of the device to ensure data consistency.

‚úÖ Example:
A DMA engine reading data that a CPU has in cache.

C) I/O Coherent with DVM Support

üí° Definition

This extends I/O coherency by adding Distributed Virtual Memory (DVM) awareness ‚Äî
meaning the I/O device also participates in address space management and TLB maintenance.

DVM = Distributed Virtual Memory
‚Üí A mechanism that synchronizes translation structures (TLBs, page tables, ASIDs) across agents in the system

IQ. Can pipelining reduce critical path? Why?
Yes ‚Äî pipelining can reduce the critical path, and that is the primary reason it allows higher clock frequency (fmax).
The critical path is the longest combinational delay between two registers.
It determines the minimum clock period ‚Üí limits max frequency.
A long combinational path forces the clock to be slow.
‚úÖ When you pipeline, you insert registers inside that long logic chain and break it into smaller pieces ‚Üí each piece has shorter delay.

IQ. In which cases pipelining can degrade performance?
Deep pipelines suffer more on mispredictions.
If instructions frequently depend on the results of previous ones, the pipeline must stall or forward data
Even if throughput is higher, pipelining increases:

clock load (more flops)
switching
speculation
‚Üí much higher energy per instruction
For battery-constrained systems, lower performance but higher efficiency may be preferable.
So performance per watt could degrade.
So the new critical path becomes shorter ‚Üí higher frequency is possible

IQ. How does pipelining improve performance if overall latency remains same or increases?
Pipelining typically does NOT reduce the latency of a single instruction.
Sometimes latency even increases because of extra pipeline stages, latches, and hazards.
But pipelining increases throughput ‚Äî more instructions completed per time.
Even though each instruction takes the same (or more) total time to finish, pipelining ensures that many instructions are in progress simultaneously, so the CPU outputs results much faster overall

IQ. How does pipelining affects frequency?
Pipelining improves fmax by reducing per-stage combinational delay.
Suppose an operation takes 9 ns combinationally:
No pipeline:
    Critical path = 9 ns ‚Üí fmax ‚âà 111 MHz
Insert pipeline registers to split into three 3-ns stages:
Pipeline:
    Critical path = 3 ns ‚Üí fmax ‚âà 333 MHz
‚úÖ fmax improved ~3√ó

IQ. Explain the difference between instruction-level parallelism (ILP) and pipelining.
Instruction-Level Parallelism refers to the extent to which instructions in a program can be executed simultaneously.
It‚Äôs a property of the code and the processor architecture ‚Äî how many instructions could be executed at once without violating dependencies (like data or control dependencies).

Pipelining is a hardware technique used to overlap the execution of multiple instructions by dividing instruction execution into stages (like an assembly line).
Each stage handles a different part of an instruction (Fetch, Decode, Execute, Memory, Write Back). While one instruction is being executed, the next one can be fetched, and the next decoded, etc.



IQ. What limits the number of pipeline stages we can have?
At first glance, it might seem like ‚Äúmore pipeline stages = faster CPU,‚Äù but in practice, there are several physical and architectural limits that constrain how deep you can make a pipeline.
1. Pipeline Overhead (Latch/Flip-Flop Delay)
Each pipeline stage needs registers or latches to hold intermediate results between stages, also cost of latches increases as we increase pipeline stage, because nu,ber of latchs increases in that case too.
These latches take time to set up and propagate signals.
If stages become too fine-grained (too short), the latch overhead becomes comparable to or larger than useful work ‚Äî reducing overall performance.

2. Pipeline Hazards (Dependencies)
Deeper pipelines mean more instructions in flight, which increases hazard complexity:
Data hazards: results needed by later instructions aren‚Äôt ready yet.
Control hazards: branches and jumps can invalidate many pipeline stages.
Structural hazards: multiple stages competing for the same hardware.
The more stages you add, the more hardware and control logic you need to handle these hazards efficiently.

3. Branch Penalty
When a branch misprediction occurs, all the instructions in the pipeline after the branch must be flushed.
The deeper the pipeline, the more cycles are wasted per misprediction.
Example:
A 5-stage pipeline might have a 3-cycle penalty.
A 20-stage pipeline (like early Intel Pentium 4 designs) can have 20+ cycles of penalty.
Thus, deeper pipelines make performance more sensitive to control flow accuracy.

4. Diminishing Returns on Clock Speed
Splitting logic into more stages can increase maximum clock frequency,
but only up to a point ‚Äî due to:
Latch overhead,
Clock distribution and synchronization difficulties,
Variability in manufacturing and voltage noise (timing uncertainty).
Beyond that point, further pipelining gives little or no clock speed benefit.

5. Increased Power and Complexity
More stages ‚Üí more registers, more forwarding paths, more complex control.
This increases power consumption, heat, and design complexity.
High-frequency deep pipelines also have higher dynamic power due to frequent clocking.

6. Instruction Dependencies and Workload Characteristics
Some workloads don‚Äôt have enough instruction-level parallelism (ILP) to keep a deep pipeline busy.
If there are frequent dependencies, deeper pipelines just stall more often ‚Äî negating the speed gains.

IQ. WAW hazard in pipeline example
A WAW (Write After Write) hazard occurs when two instructions write to the same register (or memory location), and the later instruction completes its write before the earlier one ‚Äî potentially overwriting the correct value.
üß© Example:
Let‚Äôs say we have a superscalar or out-of-order processor (since WAW hazards don‚Äôt happen in a simple in-order 5-stage RISC pipeline)
I1: ADD R1, R2, R3    ; R1 = R2 + R3
I2: MUL R1, R4, R5    ; R1 = R4 * R5
‚úÖ Here, I1 writes to R1 before I2 ‚Äî no WAW hazard (in-order execution ensures this).

If the processor allows out-of-order execution, I2 might finish earlier than I1 (for example, because I1 is waiting on a memory access).

Instruction	Operation	Write-back Cycle
I1: ADD R1, R2, R3	Addition (slow)	Cycle 8
I2: MUL R1, R4, R5	Multiplication (fast)	Cycle 6

‚û°Ô∏è I2 writes to R1 before I1, even though I1 appears earlier in program order.
That means the final value in R1 (from I2) could be overwritten incorrectly by I1.
This is a WAW hazard.
üõ†Ô∏è How CPUs avoid WAW hazards

In-order write-back:
Force instructions to write results in program order, even if they execute out-of-order.
Register renaming:
Assign each write a new physical register, so two instructions writing the same logical register don‚Äôt conflict

IQ. Which Hazard occur only in in-order pipelines ?

Actually, none of the name hazards occur only in in-order pipelines ‚Äî but some occur only in out-of-order pipelines.
To clarify:
RAW (Read After Write) happens in both in-order and out-of-order pipelines.
‚Üí It‚Äôs the most common hazard in a classic 5-stage RISC pipeline.

WAR (Write After Read) and WAW (Write After Write) happen only in out-of-order (or superscalar) pipelines.
‚Üí Because in in-order pipelines, writes always happen in the original program order, so these cannot occur.
Final Answer:
The RAW (Read After Write) hazard occurs in in-order pipelines.


                                                                                 

                                                                                 +++++++++++++++++++++
                                                                                      DATA HAZARDS
                                                                                 +++++++++++++++++++++
üí¨ Intermediate:
How does forwarding (bypassing) resolve RAW hazards?
Why can‚Äôt forwarding always eliminate stalls (e.g., load-use hazard)?
How does forwarding (bypassing) resolve RAW hazards?
How do we detect a data hazard in hardware?
(hint: hazard detection unit logic in ID stage)
What is register renaming and how does it remove WAR/WAW hazards?
                                                                                 
üí¨ Advanced / Microarchitecture Focus:
Describe how a Tomasulo algorithm handles data hazards.
In out-of-order execution, how do you maintain program order correctness when renaming registers?
Explain how a Reorder Buffer (ROB) interacts with register renaming.
What is the difference between physical registers and architectural registers?                                                                                 
                                                                  
                                                                               ++++++++++++++++++++
                                                                                 CONTROL HAZARDS
                                                                              +++++++++++++++++++++
IQ.What happens on a branch misprediction, and which pipeline stages are flushed?
When a branch is mispredicted, all instructions that entered the pipeline after the branch (i.e., fetched along the wrong path) must be flushed. In a classic 5-stage pipeline where the branch outcome is resolved in the EX stage, the IF and ID stages are flushed. The correct PC (either target or next sequential) is then loaded into the fetch stage, and instruction fetching restarts from there.
In deeper or superscalar pipelines:
All stages after the branch resolution stage (where misprediction is detected) and before the instruction retirement/commit stage are flushed.                                                                                
When misprediction is detected in EX:

The pipeline flushes IF and ID stages (instructions behind the branch that are not yet committed).
The branch itself continues normally (it will write back PC, etc.).
The correct instruction fetch begins from the right target address.
‚úÖ So in a classic 5-stage pipeline, the IF and ID stages are flushed on a misprediction.

üß© Scenario Setup
Let‚Äôs say we have this sequence:
Cycle N: Branch instruction (BNE R1, R2, LABEL)
Cycle N+1: Next sequential instruction I1 (wrong path)
Cycle N+2: Next sequential instruction I2 (wrong path)

The branch is predicted ‚Äúnot taken‚Äù, but in reality, the branch should be taken.
The misprediction is detected in the EX stage when the branch condition is actually evaluated.
| Cycle  | IF      | ID      | EX     | MEM    | WB     | Notes                                |
| ------ | ------- | ------- | ------ | ------ | ------ | ------------------------------------ |
| **1**  | BRANCH  | ‚Äî       | ‚Äî      | ‚Äî      | ‚Äî      | Fetch branch                         |
| **2**  | I1      | BRANCH  | ‚Äî      | ‚Äî      | ‚Äî      | Branch in ID                         |
| **3**  | I2      | I1      | BRANCH | ‚Äî      | ‚Äî      | Branch in EX ‚Üí *resolved here*       |
| **4**  | (flush) | (flush) | ‚Äî      | BRANCH | ‚Äî      | Wrong-path I1, I2 flushed            |
| **5**  | TARGET  | ‚Äî       | ‚Äî      | ‚Äî      | BRANCH | Fetch correct target instruction     |
| **6**  | I_T1    | TARGET  | ‚Äî      | ‚Äî      | ‚Äî      | Pipeline refilled along correct path |
| **7+** | ...     | ...     | ...    | ...    | ...    | Normal execution resumes             |

What happens at Cycle 3‚Äì4:
The branch is in EX, so the CPU knows the prediction was wrong.
It immediately:
Flushes instructions in IF and ID (I1 and I2).
Redirects PC to the correct target address (LABEL).
In Cycle 4, the fetch stage is stalled or bubbled (while redirection takes effect).
From Cycle 5, fetch begins at the correct branch target.                                                                                 
‚úÖ Flushed stages: IF and ID
‚úÖ Corrected stage: EX (where misprediction is detected)

The penalty is roughly number of pipeline stages between IF and branch resolution

                                                   
IQ. What is the branch penalty?
Answer:
The branch penalty is the number of lost cycles due to a branch instruction ‚Äî from the time the branch is fetched until the correct next instruction is known.
Example:
If branch resolution takes 3 cycles ‚Üí branch penalty = 3 cycles.

IQ. What is a Branch Target Buffer (BTB)?
Answer:
A Branch Target Buffer is a hardware cache that stores:
The address of branch instructions, and
Their predicted target addresses.

IQ. What is a branch delay slot?
A branch delay slot is an instruction immediately following a branch that is always executed, whether or not the branch is taken.
                                                   
IQ. Why do deeper pipelines worsen control hazards?
Answer:
Because the branch resolution point moves farther from the fetch stage.
That means more instructions are fetched speculatively before the branch outcome is known ‚Äî increasing the number of instructions to flush on a misprediction.
Example:
5-stage pipeline ‚Üí 2-cycle penalty
20-stage pipeline ‚Üí up to 20-cycle penalty

IQ. Why can‚Äôt control hazards be completely eliminated?
Because some branches are inherently unpredictable (data-dependent), and even perfect prediction can‚Äôt prevent pipeline flushes on occasional mispredictions.

IQ. Why does increasing pipeline depth beyond a point not increase performance?
What pipeline depth means
In a pipelined processor, an instruction‚Äôs execution is split into stages (like fetch, decode, execute, etc.), and multiple instructions overlap in these stages.
A deeper pipeline means more stages, each doing less work per cycle, so the clock frequency can be higher.
Ideally, performance ‚àù (clock frequency √ó instructions per cycle (IPC)).
‚öôÔ∏è 2. Why deeper pipelines initially improve performance
When you first start deepening the pipeline:
Each stage becomes smaller and faster.
The clock period shortens.
The processor can run at a higher clock rate.
So at first, the throughput improves roughly linearly with added stages.
üß® 3. Why performance eventually stops improving (and can even get worse)
Beyond a certain point, the costs outweigh the benefits:
a. Pipeline overhead
Each stage needs latches/registers to hold intermediate values.
These introduce latency and power overhead.
When the logic per stage gets too small, register setup and hold times dominate the cycle time.
So even if you add stages, you can‚Äôt keep increasing the clock rate much further.
b. Branch misprediction penalties
In deeper pipelines, a branch misprediction causes a flush of more stages.
Penalty = pipeline depth √ó clock period.
So if your pipeline has 20+ stages (like Pentium 4), a single mispredicted branch wastes many cycles.
This hurts average IPC, canceling out clock-speed gains.
c. Data and control hazards
With more stages:
Data dependencies span more stages ‚Üí more complex forwarding and stalling logic.
Control hazards (like jumps and branches) take longer to resolve ‚Üí more stalls.
So the pipeline becomes more fragile and inefficient.
d. Diminishing returns on clock frequency
Physical limits (like wire delays and latch overheads) prevent you from proportionally increasing clock speed with each extra stage.
e. Power and heat constraints
More stages ‚Üí more registers ‚Üí more dynamic power.
Past a point, thermal and power limits prevent running the chip at higher frequencies.
üßÆ 4. Putting it all together
Pipeline Depth	Clock Speed	IPC (efficiency)	Net Performance
5 ‚Üí 10 stages	‚Üë Clock	Slight ‚Üì IPC	‚Üë Performance
10 ‚Üí 20 stages	‚Üë Small	‚Üì‚Üì IPC (branch penalties, stalls)	‚âà Same or ‚Üì Performance
20+ stages	Minimal ‚Üë	Severe ‚Üì IPC	‚Üì Performance
üß† 5. Real-world example
Pentium 4 (NetBurst) used a 31-stage pipeline to hit high GHz speeds ‚Äî but poor IPC and high power made it slower (per clock) than earlier Pentiums.
Later designs (Intel Core, AMD Zen, ARM cores) returned to shorter pipelines (10‚Äì15 stages) for better overall performance and efficiency.
                                                   
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
NUMERICAL PROBLEMS
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
IQ.You have a multiply-accumulate operation:
   Y = A * B + C
   How do you pipeline this in RTL to meet timing?
ANS: 4 Stages
1 stage: Data fetch
2 stage: A*B
3 stage: data_x + C
4 stage: write output to register

IQ. There is a pipeline design failing timing. What do you do? ‚Üí Add pipeline stages / balance registers

IQ. Read difference beween Software Pipelining and HLS Pepelining.

IQ. What is SKID BUFFER ?

IQ. 


++++++++++++++++
LATER
++++++++++++++++
IQ. Given an ALU with 3-stage pipeline, write logic to feed inputs every cycle and collect outputs.

Systolic Arrays: Specialized Accelerators.
---------------------------------------------------------
Goal: 
  Design an accelerator that has simple, regular design, high concurrency, balanced computation, balancing I/O memory bandwidth. 
  Maximize data reuse and parallel computation, minimize memory access.
Idea: Replace single PE with an array of PE
Helps: To maximize coputation done on a single piece of data.

Difference from pipelinine ?
These have individual PEs.
Array structure can be non linear and multidimensional
PE connections can be multidirectional
PE can have local memory and execute kernels

Lets' suppose, you have to inputs A and B having 3x3 matrix data and you want to multiply that.
1 way of doing this is keep final result in PE.
2 way of doing is move the final result somewhere else.

https://www.youtube.com/watch?v=LecZfREuWvk&list=PL5Q2soXY2Zi_ZMtqz1r-GHm-zzuE1QfIg&index=9
Time - 38:37, see  explanation of matrix multiplication in a systolic array.

Advantages:
Principle followed: efficiently used memory bandwidth.
Specialized computation happening in PE.
Improved efficiency, high concurrency, simple design
Good to do more with less memory bandwidth.

Downside:
It's Specialized: Not generally applicable, because computation needs to fit the PE function organization.

More info:
Each PE can have its own data and Instruction memory
Data memory to store partial and temporary results
This leads to stream processing, pipeline parallelism
More generally staged execution

Papers:
Google VPU 2021 paper
Google TPU paper ISCA 2017 (MOST CITED PAPER IN HISTORY)



Example: Matrix Multiplication on Systolic Array

Letâ€™s compute C = A Ã— B, where:
	â€¢	A is MÃ—N
	â€¢	B is NÃ—P
	â€¢	Result C is MÃ—P

PE Operation

Each PE at position (i,j) computes:
C_{i,j} = \sum_{k=0}^{N-1} A_{i,k} Ã— B_{k,j}

â¸»

Dataflow
	1.	Elements of A enter from the left (one row per cycle).
	2.	Elements of B enter from the top (one column per cycle).
	3.	Each PE:
	â€¢	Multiplies inputs A_{i,k} and B_{k,j},
	â€¢	Adds to the running sum,
	â€¢	Passes A to the next PE in the row, B down the column.
	4.	After N cycles, every PE holds a final partial sum for one element of C.
3. Example: Matrix Multiplication on Systolic Array

Letâ€™s compute C = A Ã— B, where:
	â€¢	A is MÃ—N
	â€¢	B is NÃ—P
	â€¢	Result C is MÃ—P

PE Operation

Each PE at position (i,j) computes:
C_{i,j} = \sum_{k=0}^{N-1} A_{i,k} Ã— B_{k,j}

â¸»

Dataflow
	1.	Elements of A enter from the left (one row per cycle).
	2.	Elements of B enter from the top (one column per cycle).
	3.	Each PE:
	â€¢	Multiplies inputs A_{i,k} and B_{k,j},
	â€¢	Adds to the running sum,
	â€¢	Passes A to the next PE in the row, B down the column.
	4.	After N cycles, every PE holds a final partial sum for one element of C.

âœ… In essence:
A systolic array is a fixed-function dataflow engine â€” unbeatable for linear algebra (especially matrix multiplication).



ðŸ’¡ 6. Real-World Example â€” Google TPU

Google TPU v1 (2015)
	â€¢	256Ã—256 systolic array
	â€¢	Each PE = 1 MAC (Multiplyâ€“Accumulate)
	â€¢	Total = 65,536 operations per cycle
	â€¢	Clocked at ~700 MHz â†’ 46 TFLOPS (8-bit integer)

A matrix â†’ â†’ â†’ â†’ 
          [PE][PE][PE]...
          [PE][PE][PE]...
          [PE][PE][PE]...
â†“ â†“ â†“ â†“ B matrix

Workflow:
	â€¢	A and B matrices stream into the array.
	â€¢	Each PE multiplies & accumulates locally.
	â€¢	Final C matrix collected at the bottom/right edge.

âœ… The TPU essentially performs entire neural network layers in hardware.

ðŸ”© 7. Example Calculation (Numeric)

Compute:

C = A Ã— B
A = \begin{bmatrix}1 & 2\\3 & 4\end{bmatrix}, \;
B = \begin{bmatrix}5 & 6\\7 & 8\end{bmatrix}

PE(0,0) computes C_{0,0} = 1Ã—5 + 2Ã—7 = 19
PE(0,1) computes C_{0,1} = 1Ã—6 + 2Ã—8 = 22
PE(1,0) computes C_{1,0} = 3Ã—5 + 4Ã—7 = 43
PE(1,1) computes C_{1,1} = 3Ã—6 + 4Ã—8 = 50

Each PE stores its partial sum locally and passes operands diagonally across cycles.

ðŸ”¹ (B) Mapping to Convolution (CNNs)
In CNNs, convolutions can be transformed into matrix multiplications (im2col) â†’ then executed on a systolic array directly.

So, systolic arrays accelerate:
	â€¢	Dense matrix ops
	â€¢	Convolutions
	â€¢	Attention mechanisms (transformers)

ðŸ”¹ (C) 3D Systolic Arrays
Used in modern architectures (e.g., TPU v3, Cerebras Wafer-Scale Engine) â€” extend systolic communication in depth, enabling 3D data reuse.


**** Can we use FPGA for Neural network acceleration ?  ->> Read about Microsoft Brainwave



ðŸ”¹ (D) Programmable Systolic Arrays
Recent AI accelerators use reconfigurable arrays (e.g., Eyeriss, Tesla D1) that can change dataflow direction or PE roles dynamically, combining the flexibility of GPUs with systolic efficiency.


âœ… In short:

A systolic array is a parallel architecture that performs matrix multiplications (and similar linear algebra) by streaming data through a grid of MAC units, achieving massive parallelism, high data reuse, and exceptional energy efficiency.
Itâ€™s the foundation of modern AI accelerators.



